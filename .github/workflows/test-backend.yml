name: Backend Tests

on:
  workflow_call:
    outputs:
      coverage:
        description: "Backend test coverage percentage"
        value: ${{ jobs.test-matrix.outputs.coverage }}

permissions:
  contents: read
  checks: write
  pull-requests: write
  security-events: write

env:
  PYTHON_VERSION: '3.13'

jobs:
  # Stage 1: Quality Gates (2-3 minutes)
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-quality-${{ env.PYTHON_VERSION }}-${{ hashFiles('backend/requirements.txt', 'backend/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-quality-${{ env.PYTHON_VERSION }}-
            ${{ runner.os }}-pip-quality-
      
      - name: Install quality tools
        run: |
          python -m pip install --upgrade pip
          pip install black isort mypy flake8 pylint vulture
          pip install types-requests types-redis types-PyYAML
      
      - name: Check code formatting (Black)
        working-directory: ./backend
        run: |
          black --check --diff app/ || {
            echo "## ❌ Code Formatting Issues Found" >> $GITHUB_STEP_SUMMARY
            echo "Run \`black app/\` to fix formatting issues" >> $GITHUB_STEP_SUMMARY
            exit 1
          }
          echo "## ✅ Code Formatting (Black)" >> $GITHUB_STEP_SUMMARY
          echo "All code is properly formatted" >> $GITHUB_STEP_SUMMARY
      
      - name: Check import sorting (isort)
        working-directory: ./backend
        run: |
          # Ensure isort uses pyproject.toml configuration
          isort --check-only --diff --settings-file=pyproject.toml app/ || {
            echo "## ❌ Import Sorting Issues Found" >> $GITHUB_STEP_SUMMARY
            echo "Run \`isort app/\` to fix import ordering" >> $GITHUB_STEP_SUMMARY
            echo "Local config uses: profile=black, multi_line_output=3" >> $GITHUB_STEP_SUMMARY
            exit 1
          }
          echo "## ✅ Import Sorting (isort)" >> $GITHUB_STEP_SUMMARY
          echo "All imports are properly sorted using pyproject.toml config" >> $GITHUB_STEP_SUMMARY
      
      - name: Linting (flake8)
        working-directory: ./backend
        run: |
          flake8 app/ --max-line-length=88 --extend-ignore=E203,W503 || {
            echo "## ❌ Linting Issues Found" >> $GITHUB_STEP_SUMMARY
            echo "Fix flake8 issues above" >> $GITHUB_STEP_SUMMARY
            exit 1
          }
          echo "## ✅ Linting (flake8)" >> $GITHUB_STEP_SUMMARY
          echo "No linting issues found" >> $GITHUB_STEP_SUMMARY
      
      - name: Type checking (mypy)
        working-directory: ./backend
        run: |
          mypy app/ --ignore-missing-imports --no-strict-optional || {
            echo "## ⚠️ Type Checking Issues Found" >> $GITHUB_STEP_SUMMARY
            echo "Review mypy output above for type issues" >> $GITHUB_STEP_SUMMARY
            echo "Consider adding type hints or mypy configuration" >> $GITHUB_STEP_SUMMARY
          }
          echo "## ✅ Type Checking (mypy)" >> $GITHUB_STEP_SUMMARY
          echo "Type checking completed" >> $GITHUB_STEP_SUMMARY

  # Stage 2: Build & Install (3-4 minutes)
  build:
    name: Build Python Environment
    runs-on: ubuntu-latest
    needs: quality-gates
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.local/lib/python*/site-packages
            backend/.pytest_cache
          key: ${{ runner.os }}-python-${{ env.PYTHON_VERSION }}-${{ hashFiles('backend/requirements.txt', 'backend/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-python-${{ env.PYTHON_VERSION }}-
            ${{ runner.os }}-python-
      
      - name: Create virtual environment and install dependencies
        working-directory: ./backend
        run: |
          python -m venv venv
          source venv/bin/activate
          python -m pip install --upgrade pip
          pip install -e .[all,test]
          pip install pytest-cov pytest-xdist pytest-timeout
          
          # Verify installation
          python -c "import app; print('Backend app module imported successfully')"
          pytest --version
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: |
            backend/venv/
            backend/app/
            backend/pyproject.toml
            backend/requirements.txt
          retention-days: 1

  # Stage 3: Test Matrix (5-8 minutes per job, parallel)
  test-matrix:
    name: Tests (${{ matrix.test-type }})
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        test-type: ['unit', 'integration', 'api']
    
    outputs:
      coverage: ${{ steps.coverage.outputs.percentage }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: backend/
      
      - name: Activate virtual environment
        working-directory: ./backend
        run: |
          chmod +x venv/bin/activate
          source venv/bin/activate
          echo "VIRTUAL_ENV=$VIRTUAL_ENV" >> $GITHUB_ENV
          echo "PATH=$VIRTUAL_ENV/bin:$PATH" >> $GITHUB_ENV
      
      - name: Run unit tests
        if: matrix.test-type == 'unit'
        working-directory: ./backend
        env:
          TESTING: true
        run: |
          source venv/bin/activate
          pytest app/tests/unit/ \
            --cov=app \
            --cov-report=xml:coverage-unit.xml \
            --cov-report=html:htmlcov-unit \
            --junit-xml=test-results-unit.xml \
            -n auto \
            --timeout=60 \
            -v
      
      - name: Run integration tests
        if: matrix.test-type == 'integration'
        working-directory: ./backend
        env:
          TESTING: true
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          source venv/bin/activate
          pytest app/tests/integration/ \
            --cov=app \
            --cov-report=xml:coverage-integration.xml \
            --cov-report=html:htmlcov-integration \
            --junit-xml=test-results-integration.xml \
            -n auto \
            --timeout=120 \
            -v
      
      - name: Run API tests
        if: matrix.test-type == 'api'
        working-directory: ./backend
        env:
          TESTING: true
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          API_BASE_URL: http://localhost:8000
        run: |
          source venv/bin/activate
          
          # Start the API server in background
          python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          API_PID=$!
          sleep 10
          
          # Run API tests
          pytest app/tests/api/ \
            --cov=app \
            --cov-report=xml:coverage-api.xml \
            --cov-report=html:htmlcov-api \
            --junit-xml=test-results-api.xml \
            -n auto \
            --timeout=90 \
            -v || TEST_EXIT_CODE=$?
          
          # Clean up API server
          kill $API_PID 2>/dev/null || true
          
          # Exit with test result
          exit ${TEST_EXIT_CODE:-0}
      
      - name: Generate coverage report
        if: always()
        working-directory: ./backend
        run: |
          source venv/bin/activate
          if [ -f coverage-${{ matrix.test-type }}.xml ]; then
            COVERAGE=$(python -c "
            import xml.etree.ElementTree as ET
            tree = ET.parse('coverage-${{ matrix.test-type }}.xml')
            root = tree.getroot()
            print(f\"{float(root.attrib['line-rate']) * 100:.1f}\")
            ")
            echo "percentage=$COVERAGE" >> $GITHUB_OUTPUT
            echo "### 📊 Coverage Report (${{ matrix.test-type }})" >> $GITHUB_STEP_SUMMARY
            echo "Coverage: $COVERAGE%" >> $GITHUB_STEP_SUMMARY
          fi
        id: coverage
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: backend-test-results-${{ matrix.test-type }}
          path: |
            backend/test-results-*.xml
            backend/coverage-*.xml
            backend/htmlcov-*/
          retention-days: 30
      
      - name: Upload coverage to Codecov
        if: matrix.test-type == 'unit'
        uses: codecov/codecov-action@v4
        with:
          file: ./backend/coverage-unit.xml
          directory: ./backend
          flags: backend,unit
          name: backend-unit-coverage
          fail_ci_if_error: false
      
      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: backend/test-results-*.xml
          check_name: "Backend Tests (${{ matrix.test-type }})"
          comment_mode: create new
          fail_on: "test failures"

  # Stage 4: Code Quality Analysis (parallel with other stage 4 jobs)
  code-quality:
    name: Code Quality Analysis
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: backend/
      
      - name: Install analysis tools
        run: |
          pip install pylint vulture
      
      - name: Activate virtual environment
        working-directory: ./backend
        run: |
          chmod +x venv/bin/activate
          source venv/bin/activate
          echo "VIRTUAL_ENV=$VIRTUAL_ENV" >> $GITHUB_ENV
          echo "PATH=$VIRTUAL_ENV/bin:$PATH" >> $GITHUB_ENV
      
      - name: Code quality analysis (pylint)
        working-directory: ./backend
        run: |
          source venv/bin/activate
          pylint app/ --fail-under=8.0 --output-format=text || {
            echo "## ⚠️ Code Quality Below Threshold" >> $GITHUB_STEP_SUMMARY
            echo "PyLint score below 8.0 - consider refactoring" >> $GITHUB_STEP_SUMMARY
          }
          echo "## ✅ Code Quality (pylint)" >> $GITHUB_STEP_SUMMARY
          echo "Code quality meets standards" >> $GITHUB_STEP_SUMMARY
      
      - name: Dead code detection (vulture)
        working-directory: ./backend
        run: |
          source venv/bin/activate
          vulture app/ --min-confidence 80 > vulture-report.txt || true
          if [ -s vulture-report.txt ]; then
            echo "## 🧹 Dead Code Detection" >> $GITHUB_STEP_SUMMARY
            echo "Potential dead code found - review vulture-report.txt" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            head -10 vulture-report.txt >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ✅ Dead Code Detection" >> $GITHUB_STEP_SUMMARY
            echo "No dead code detected" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload code quality reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: backend-code-quality-reports
          path: |
            backend/vulture-report.txt
          retention-days: 30 